//
//     Generated by class-dump 3.5-MH (64 bit).
//
//  Copyright (C) 1997-2019 Steve Nygard.
//

#import <objc/NSObject.h>

#import <AssistantUI/AFQueueDelegate-Protocol.h>
#import <AssistantUI/AFUISpeechSynthesis-Protocol.h>
#import <AssistantUI/AFUISpeechSynthesisElementDelegate-Protocol.h>
#import <AssistantUI/VSSpeechSynthesizerDelegate-Protocol.h>

@class AFQueue, AFSiriClientStateManager, AFVoiceInfo, NSMutableArray, NSMutableDictionary, NSString, VSSpeechSynthesizer;
@protocol AFUISpeechSynthesisDelegate, AFUISpeechSynthesisLocalDelegate, OS_dispatch_group, OS_dispatch_queue;

@interface AFUISpeechSynthesis : NSObject <AFQueueDelegate, AFUISpeechSynthesisElementDelegate, VSSpeechSynthesizerDelegate, AFUISpeechSynthesis>
{
    VSSpeechSynthesizer *_synthesizer;
    AFSiriClientStateManager *_siriClientStateManager;
    unsigned int _sessionID;
    AFVoiceInfo *_outputVoice;
    NSMutableDictionary *_availableVoicesForLanguage;
    NSObject<OS_dispatch_queue> *_processingElementsQueue;
    NSObject<OS_dispatch_queue> *_pendingElementsQueue;
    NSObject<OS_dispatch_group> *_pendingElementsGroup;
    id<AFUISpeechSynthesisDelegate> _delegate;
    id<AFUISpeechSynthesisLocalDelegate> _localDelegate;
    AFQueue *_elementQueue;
    NSMutableArray *_activeElements;
    NSMutableDictionary *_delayedElements;
}

@property (readonly, nonatomic, getter=_activeElements) NSMutableArray *activeElements; // @synthesize activeElements=_activeElements;
@property (readonly, copy) NSString *debugDescription;
@property (readonly, nonatomic, getter=_delayedElements) NSMutableDictionary *delayedElements; // @synthesize delayedElements=_delayedElements;
@property (strong, nonatomic) id<AFUISpeechSynthesisDelegate> delegate; // @synthesize delegate=_delegate;
@property (readonly, copy) NSString *description;
@property (readonly, nonatomic, getter=_elementQueue) AFQueue *elementQueue; // @synthesize elementQueue=_elementQueue;
@property (readonly) unsigned long long hash;
@property (weak, nonatomic) id<AFUISpeechSynthesisLocalDelegate> localDelegate; // @synthesize localDelegate=_localDelegate;
@property (readonly) Class superclass;

- (void).cxx_destruct;
- (id)_activeElementWithPresynthesizedAudioRequest:(id)arg1;
- (id)_activeElementWithSpeechRequest:(id)arg1;
- (void)_cancelByCancellingActiveElementsOnly:(BOOL)arg1;
- (void)_enqueueText:(id)arg1 audioData:(id)arg2 identifier:(id)arg3 language:(id)arg4 gender:(id)arg5 isPhonetic:(BOOL)arg6 provisionally:(BOOL)arg7 eligibleAfterDuration:(double)arg8 delayed:(BOOL)arg9 canUseServerTTS:(BOOL)arg10 preparationIdentifier:(id)arg11 shouldCache:(BOOL)arg12 synthesizesWhileRecording:(BOOL)arg13 completion:(CDUnknownBlockType)arg14 animationIdentifier:(id)arg15 analyticsContext:(id)arg16 speakableContextInfo:(id)arg17;
- (id)_filterVoices:(id)arg1 gender:(id)arg2;
- (void)_findVoiceForLanguage:(id)arg1 gender:(id)arg2 completion:(CDUnknownBlockType)arg3;
- (long long)_genderForString:(id)arg1;
- (void)_handleAudioData:(id)arg1 completion:(CDUnknownBlockType)arg2;
- (void)_handleText:(id)arg1 completion:(CDUnknownBlockType)arg2;
- (BOOL)_isSynthesisQueueEmpty;
- (void)_processElementQueue;
- (void)_processProvisionalElements;
- (void)_setSiriClientStateManager:(id)arg1;
- (void)_setSynthesizer:(id)arg1;
- (id)_siriClientStateManager;
- (id)_synthesizer;
- (void)cancel;
- (void)enqueueAudioData:(id)arg1 identifier:(id)arg2 provisionally:(BOOL)arg3 eligibleAfterDuration:(double)arg4 completion:(CDUnknownBlockType)arg5;
- (void)enqueuePhaticWithCompletion:(CDUnknownBlockType)arg1;
- (void)enqueueText:(id)arg1 identifier:(id)arg2 completion:(CDUnknownBlockType)arg3;
- (void)enqueueText:(id)arg1 identifier:(id)arg2 language:(id)arg3 gender:(id)arg4 isPhonetic:(BOOL)arg5 provisionally:(BOOL)arg6 eligibleAfterDuration:(double)arg7 delayed:(BOOL)arg8 canUseServerTTS:(BOOL)arg9 preparationIdentifier:(id)arg10 completion:(CDUnknownBlockType)arg11 animationIdentifier:(id)arg12 analyticsContext:(id)arg13 speakableContextInfo:(id)arg14;
- (id)init;
- (void)invalidate;
- (void)invalidateOnMainThread;
- (BOOL)isSpeaking;
- (void)isSynthesisQueueEmpty:(CDUnknownBlockType)arg1;
- (void)prewarmIfNeeded;
- (void)processDelayedItem:(id)arg1;
- (void)queue:(id)arg1 didEnqueueObjects:(id)arg2;
- (void)setAudioSessionID:(unsigned int)arg1;
- (void)setOutputVoice:(id)arg1;
- (void)skipCurrentSynthesis;
- (void)speechSynthesisElementSynthesisEligibilityDidChange:(id)arg1;
- (void)speechSynthesizer:(id)arg1 didFinishPresynthesizedAudioRequest:(id)arg2 withInstrumentMetrics:(id)arg3 error:(id)arg4;
- (void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 successfully:(BOOL)arg3 phonemesSpoken:(id)arg4 withError:(id)arg5;
- (void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 withInstrumentMetrics:(id)arg3;
- (void)speechSynthesizer:(id)arg1 didStartPresynthesizedAudioRequest:(id)arg2;
- (void)speechSynthesizer:(id)arg1 didStartSpeakingRequest:(id)arg2;
- (void)speechSynthesizer:(id)arg1 didStopPresynthesizedAudioRequest:(id)arg2 atEnd:(BOOL)arg3 error:(id)arg4;

@end

